{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR20GV2CAuhH"
      },
      "source": [
        "# Obtención de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install lxml\n",
        "# !pip install pandas\n",
        "# !pip install beautifulsoup4\n",
        "# !pip install pyarrow\n",
        "# !pip install clint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UMfX2cDsgV_M"
      },
      "outputs": [],
      "source": [
        "# Importamos librerías\n",
        "import os\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "import requests\n",
        "import time\n",
        "import datetime\n",
        "from distutils.command.build_scripts import first_line_re\n",
        "import requests\n",
        "from clint.textui import puts, colored, indent\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZECYRJbHbi1V"
      },
      "source": [
        "## SIAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGpXj6vt6YyF"
      },
      "source": [
        "### Creamos catálogos con los identificadores para la API desde el JSON: Victor-dict.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nKpjsfYoAuhl"
      },
      "outputs": [],
      "source": [
        "# Creamos el folder para los distintos catálogos (uno por filtro)\n",
        "if not os.path.exists('Catalogos_API_SIAP'):\n",
        "    os.mkdir(\"Catalogos_API_SIAP\")\n",
        "\n",
        "# Cargamos el json\n",
        "df = pd.read_json('SIAP_API_dict.json',orient='index')\n",
        "\n",
        "# Creamos una lista con los nombres de los filtros y el nombre que tendrán los catálogos\n",
        "tag = [\"municipio\",\"anioagric\",\"cicloProd\",\"modalidad\",\"entidad\",\"cultivo\",\"distrito\",\"mesagric\"]\n",
        "name_csv = ['Municipio','Anio_Agricola','Ciclo_Prod','Modalidad','Entidad','Cultivo','Distrito',\"Mes_Agricola\"]\n",
        "\n",
        "# Iteramos sobre los filtros\n",
        "for i in range(8):\n",
        "    # Toma los datos pertenecientes a tag\n",
        "    df_aux2 = df.loc[df.index.str.startswith(tag[i])]\n",
        "    df_aux = df_aux2.copy()\n",
        "    # Elimina la str del tag+_ de la columna index\n",
        "    df_aux.index = df_aux.index.str.replace(tag[i]+'_', \"\")\n",
        "    # Convierte el indice en columna\n",
        "    df_aux.reset_index(inplace=True)\n",
        "    # Cambia los nombres de las columnas\n",
        "    df_aux.rename(columns={0: \"ID\",\"index\":\"Name\"}, inplace=True)\n",
        "    # Crea el path donde se guardara\n",
        "    ruta_completa = os.path.join(\"Catalogos_API_SIAP\",name_csv[i])\n",
        "    # Guardar el DataFrame en el archivo CSV en la carpeta \"Catalogos_API_SIAP\"\n",
        "    df_aux.to_csv(ruta_completa + '.csv', index=False)\n",
        "\n",
        "#Elimina los df\n",
        "del df_aux, df_aux2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiFFWRv7Auhw"
      },
      "source": [
        "### Descarga de de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xRsE3clfAuhx"
      },
      "outputs": [],
      "source": [
        "# Creacion del folder Raw\n",
        "if not os.path.exists('Raw'):\n",
        "    os.mkdir(\"Raw\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creación del folder SIAP\n",
        "if not os.path.exists('Raw/SIAP/'):\n",
        "    os.mkdir(\"Raw/SIAP/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "A9ie4VAdAuhx"
      },
      "outputs": [],
      "source": [
        "# Comando para ignorar warnings (salen en cada request)\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yequPVhdAuhy"
      },
      "outputs": [],
      "source": [
        "# Creamos iterables para años, meses y cultivos\n",
        "anio_arr = pd.read_csv('./Catalogos_API_SIAP/Anio_Agricola.csv').ID.to_list()\n",
        "cultivo_arr = pd.read_csv('./Catalogos_API_SIAP/Cultivo.csv').ID.to_list()\n",
        "mes_arr = pd.read_csv('./Catalogos_API_SIAP/Mes_Agricola.csv').ID.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aA-d0oo-Auhy"
      },
      "outputs": [],
      "source": [
        "# En el iterable de cultibos eliminamos la opción 0\n",
        "cultivo_arr.remove(0) # 0: Todos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4Mu5l6SybaXv"
      },
      "outputs": [],
      "source": [
        "# En SIAP creamos una carpeta para cada año\n",
        "for i in anio_arr:\n",
        "    if not os.path.exists('Raw/SIAP/'+str(i)):\n",
        "        os.mkdir(\"Raw/SIAP/\"+str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MDw4TsGQAuh0"
      },
      "outputs": [],
      "source": [
        "# Función para hacer un request a la API\n",
        "def API_SIAP(anio,mes,cultivo):\n",
        "  \"\"\"Esta función permite hacer un request a la API de avance agrícola mensual y recibe como argumento el año,\n",
        "     mes y cultivo del que queremos obtener la información. Los demás filtros reciben un valor fijo.\"\"\"\n",
        "\n",
        "  # Endpoint\n",
        "  url = \"https://nube.siap.gob.mx/avance_agricola/\"\n",
        "\n",
        "  # Diccionario con atributos del request\n",
        "  payload = {'xajax': 'reporte', # Para obtener la tabla\n",
        "  'xajaxr': '1696449941927', # Timestamp UNIX\n",
        "  'xajaxargs[]': [\n",
        "      '1', # 1: Desglose por estados, 2: Cultivo total\n",
        "      str(anio), # Anio\n",
        "      '5', # ID Ciclo\n",
        "      '3', # ID Modalidad\n",
        "      '0', # ID Estado (0: Nacional)\n",
        "      '--',\n",
        "      '--',\n",
        "      str(cultivo), # ID Cultivo\n",
        "      '200201',\n",
        "      '0',\n",
        "      '1', # 1: Por municipio\n",
        "      'undefined',\n",
        "      'undefined',\n",
        "      'undefined',\n",
        "      str(mes) # Valor del mes: va de 1 a 8, con 1 siendo Enero y 8 Agosto\n",
        "      ]\n",
        "  }\n",
        "\n",
        "  headers = {\n",
        "    'Cookie': 'PHPSESSID=45ri2k73cbp2iptcrufu88p360'\n",
        "  }\n",
        "\n",
        "  # Hacemos el request\n",
        "  response = requests.request(\"POST\", url, headers=headers, data=payload, verify=False)\n",
        "  response.encoding='ISO-8859-1'\n",
        "\n",
        "  # Regresamos un string con el XML con la tabla que contiene los datos solicitados\n",
        "  return response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8B-UPvA2FHfa"
      },
      "outputs": [],
      "source": [
        "# Iteramos anidadamente sobre los años, meses y cultivos de nuestro interés\n",
        "\n",
        "for anio in anio_arr:     # Iteramos en los años\n",
        "    for mes in mes_arr:   # Iteramos en los meses\n",
        "\n",
        "        # Lista con el nombre de nuestras columnas\n",
        "        columnas = [\"Entidad\", \"Municipio\", \"Superficie Sembrada\", \"Superficie Cosechada\", \"Superficie Siniestrada\", \"Produccion\", \"Rendimiento\",\"Anio\", \"Mes\", \"Cultivo\"]\n",
        "        df_raw = pd.DataFrame(columns=columnas)  # Creamos un DataFrame vacío con estas columnas\n",
        "\n",
        "        for cultivo in cultivo_arr:                 # Iteramos en los cultivos\n",
        "            xml_data = API_SIAP(anio,mes,cultivo)   # Hcemos el API request\n",
        "            soup = BeautifulSoup(xml_data, 'lxml')  # Parseamos el XML con BeautifulSoup usando el analizador XML (lxml)\n",
        "\n",
        "            # Encontramos la tabla por su ID\n",
        "            tablas = soup.find_all('table', id='Resultados-reporte') #***************************************************************************#\n",
        "\n",
        "            if len(tablas) == 0:  #**************************************************************************************************************#\n",
        "                continue          #**************************************************************************************************************#\n",
        "            \n",
        "            elif mes in (10, 11, 12):    #**************************************************************************************************************#\n",
        "                tabla = tablas[-1]       #************************************************************************************************************#\n",
        "            \n",
        "            else:                     #**************************************************************************************************************#\n",
        "                tabla = tablas[0]     #**************************************************************************************************************#\n",
        "                \n",
        "            # Inicializamos listas para almacenar los datos\n",
        "            datos = []\n",
        "\n",
        "            # Iteramos a través de las filas de la tabla\n",
        "            for fila in tabla.find_all('tr')[1:]:  # Ignoramos la primera fila de encabezados\n",
        "                columnas = fila.find_all('td')     # Identificamos todas las celdas\n",
        "                if len(columnas) == 0:             # Ignoramos las filas vacías\n",
        "                    continue\n",
        "\n",
        "                # Extraemos los datos relevantes de cada columna\n",
        "                #posicion = columnas[0].get_text()\n",
        "                entidad = columnas[1].get_text()\n",
        "                municipio = columnas[2].get_text()\n",
        "                superficie_sembrada = columnas[3].get_text()\n",
        "                superficie_cosechada = columnas[4].get_text()\n",
        "                superficie_siniestrada = columnas[5].get_text()\n",
        "                produccion = columnas[6].get_text()\n",
        "                rendimiento = columnas[7].get_text()\n",
        "\n",
        "                # Agregamos los datos a la lista\n",
        "                datos = [\n",
        "                    entidad, municipio,\n",
        "                    superficie_sembrada, superficie_cosechada,\n",
        "                    superficie_siniestrada, produccion, rendimiento,\n",
        "                    anio, mes, cultivo\n",
        "                ]\n",
        "\n",
        "                # Agregamos estos datos al DataFrame\n",
        "                df_raw.loc[len(df_raw)] = datos\n",
        "\n",
        "        # Guardamos un CSV cuyo nombre sigue el formato: \"Avance_agricola_año_mes.csv\"\n",
        "        name_csv = 'Avance_Agricola_'+str(anio)+'_'+str(mes)\n",
        "        df_raw.to_csv('./Raw/SIAP/'+str(anio)+'/'+name_csv+'.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8yRDiR0gDHG"
      },
      "source": [
        "## SNIIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creacion de folder en raw\n",
        "if not os.path.exists('raw/SNIIM'):\n",
        "    os.mkdir(\"raw/SNIIM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Descarga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VzivuSd6gEy8"
      },
      "outputs": [],
      "source": [
        "class ScrapperMarketAgriculture:\n",
        "    total_records = 0\n",
        "    inserted_records = 0\n",
        "    current_product = 'None'\n",
        "    first_print = True\n",
        "\n",
        "    base_url = 'http://www.economia-sniim.gob.mx/NUEVO/Consultas/MercadosNacionales/PreciosDeMercado/Agricolas'\n",
        "    init_urls = [\n",
        "        ['Frutas y Hortalizas', '/ConsultaFrutasYHortalizas.aspx', '/ResultadosConsultaFechaFrutasYHortalizas.aspx'],\n",
        "        ['Flores', '/ConsultaFlores.aspx?SubOpcion=5', '/ResultadosConsultaFechaFlores.aspx'],\n",
        "        ['Granos', '/ConsultaGranos.aspx?SubOpcion=6', '/ResultadosConsultaFechaGranos.aspx'],\n",
        "        ['Aceites', '/ConsultaAceites.aspx?SubOpcion=8', '/ResultadosConsultaFechaAceites.aspx']\n",
        "    ]\n",
        "\n",
        "    last_year = 2023\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.is_historic = kwargs.get('is_historic', True)\n",
        "        self.df = pd.DataFrame()\n",
        "\n",
        "    def read_category(self, category, url, url_form):\n",
        "        category_page = requests.get(self.base_url + url)\n",
        "        category_page = BeautifulSoup(category_page.content, features=\"html.parser\")\n",
        "\n",
        "        products = [(product.getText(), product['value'], ) for product in category_page.select_one('select#ddlProducto').find_all('option')]\n",
        "\n",
        "        for product in products[105:]:\n",
        "            product_name, product_id = product\n",
        "            if product_id == '-1':\n",
        "                continue\n",
        "\n",
        "            if self.current_product != 'None':\n",
        "              prod = re.sub(r'\\s','_',self.current_product)\n",
        "              self.df.to_csv(f'./raw/SNIIM/sniim_product_{prod}.csv', index=False)\n",
        "            self.current_product = str(product_name).lower().replace('-','').replace('  ', '_')\n",
        "            self.first_print = True\n",
        "            self.df = pd.DataFrame()\n",
        "\n",
        "            with indent(4):\n",
        "                puts(colored.magenta(\"Producto: {}\".format(self.current_product)))\n",
        "\n",
        "            if self.is_historic:\n",
        "                for year in range(2018, 2024):\n",
        "                    payload = {\n",
        "                        'fechaInicio':'01/01/{0}'.format(str(year)),\n",
        "                        'fechaFinal':'01/01/{0}'.format(str(year + 1)),\n",
        "                        'ProductoId':product_id,\n",
        "                        'OrigenId':'-1',\n",
        "                        'Origen':'Todos',\n",
        "                        'DestinoId':'-1',\n",
        "                        'Destino':'Todos',\n",
        "                        'PreciosPorId':'2',\n",
        "                        'RegistrosPorPagina':'1000'\n",
        "                    }\n",
        "\n",
        "                    if not self.gather_prices(payload, url_form):\n",
        "                        continue\n",
        "            else:\n",
        "                today = datetime.datetime.today()\n",
        "                deleta = datetime.timedelta(days=-1)\n",
        "                payload = {\n",
        "                        'fechaInicio':'{}'.format(today.strftime('%d/%m/%Y')),\n",
        "                        'fechaFinal':'{}'.format((today).strftime('%d/%m/%Y')),\n",
        "                        'ProductoId':product_id,\n",
        "                        'OrigenId':'-1',\n",
        "                        'Origen':'Todos',\n",
        "                        'DestinoId':'-1',\n",
        "                        'Destino':'Todos',\n",
        "                        'PreciosPorId':'2',\n",
        "                        'RegistrosPorPagina':'1000'\n",
        "                    }\n",
        "\n",
        "                if not self.gather_prices(payload, url_form):\n",
        "                    continue\n",
        "\n",
        "        return\n",
        "\n",
        "    def scraping(self):\n",
        "        self.total_records = 0\n",
        "        self.inserted_records = 0\n",
        "\n",
        "        for category, url, url_form in self.init_urls:\n",
        "            self.read_category(category, url, url_form)\n",
        "            time.sleep(60)\n",
        "\n",
        "    def gather_prices(self, payload, url_form):\n",
        "        with indent(4):\n",
        "            puts(colored.blue(\"Peticion: {}\".format(str(payload))))\n",
        "\n",
        "        response = requests.get(self.base_url + url_form, params=payload)\n",
        "        time.sleep(30)\n",
        "        if response.status_code != 200:\n",
        "            with indent(4):\n",
        "                puts(colored.red(\"Error en la peticion HTTP: {}\".format(str(response.text))))\n",
        "            return False\n",
        "\n",
        "        product_prices = BeautifulSoup(response.content, features=\"html.parser\")\n",
        "\n",
        "        try:\n",
        "            table_prices = product_prices.select_one('table#tblResultados')\n",
        "        except Exception as error:\n",
        "            with indent(4):\n",
        "                puts(colored.red(\"Error en el parseo: {}\".format(str(error))))\n",
        "            return False\n",
        "\n",
        "        fields = ('fecha', 'presentacion', 'origen', 'destino', 'precio_min', 'precio_max', 'precio_frec', 'obs')\n",
        "        counter_row = 0\n",
        "\n",
        "        for observation in table_prices.find_all('tr'):\n",
        "            if counter_row > 1:\n",
        "                row = {}\n",
        "                counter_field = 0\n",
        "                if self.first_print:\n",
        "                  self.first_print = False\n",
        "                for metric in observation.find_all('td'):\n",
        "                    row[fields[counter_field]] = metric.getText()\n",
        "                    counter_field += 1\n",
        "\n",
        "                row['name'] = self.current_product\n",
        "                df2 = pd.DataFrame(row, index=[0]) \n",
        "                self.df = pd.concat([self.df, df2])\n",
        "\n",
        "            self.total_records += 1\n",
        "            counter_row += 1\n",
        "            if self.total_records % 1000 == 0:\n",
        "              prod = re.sub(r'\\s','_',self.current_product)\n",
        "              self.df.to_csv(f'./raw/SNIIM/sniim_product_{prod}.csv', index=False) \n",
        "        return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "  agricola = ScrapperMarketAgriculture()\n",
        "  agricola.scraping()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
